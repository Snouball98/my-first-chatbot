#!/usr/bin/env python3
"""
Streamlit app: SoccerBot

Features:
- Detects soccer-related prompts and applies a SoccerBot system instruction
- Mock local tools: get_match_summary, get_player_stats (JSON strings)
- If prompt contains 'ê²½ê¸° ìš”ì•½:' or 'ì„ ìˆ˜ í†µê³„:' it will call local tools and then ask the model to expand the result

Before running:
- create a `.env` with `AZURE_OAI_KEY` and `AZURE_OAI_ENDPOINT` (and optionally `AZURE_OAI_DEPLOYMENT`)
- install: `pip install streamlit python-dotenv openai requests`

Run:
    streamlit run app.py
"""

import os
import json
import re
import time
import streamlit as st
from dotenv import load_dotenv
from openai import AzureOpenAI

load_dotenv()

st.set_page_config(page_title="SoccerBot", layout="wide")
st.title("âš½ SoccerBot")

# Azure OpenAI client
AZURE_ENDPOINT = os.getenv("AZURE_OAI_ENDPOINT")
AZURE_KEY = os.getenv("AZURE_OAI_KEY")
DEPLOYMENT = os.getenv("AZURE_OAI_DEPLOYMENT", "gpt-4o-mini")

if not AZURE_KEY or not AZURE_ENDPOINT:
    st.error("í™˜ê²½ë³€ìˆ˜ `AZURE_OAI_KEY` ë˜ëŠ” `AZURE_OAI_ENDPOINT`ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

try:
    client = AzureOpenAI(azure_endpoint=AZURE_ENDPOINT, api_key=AZURE_KEY, api_version="2024-05-01-preview")
except Exception as e:
    client = None
    st.warning(f"AzureOpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# ê°„ë‹¨í•œ ì¶•êµ¬ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì§€
SOCCER_KEYWORDS = ["ì¶•êµ¬", "ì„ ìˆ˜", "ê²½ê¸°", "ê³¨", "ë¦¬ê·¸", "ë“ì ", "ì–´ì‹œìŠ¤íŠ¸", "í¬ë©”ì´ì…˜", "ì „ìˆ ", "ë§¨ìœ ", "ë¦¬ë²„í’€", "ì†í¥ë¯¼"]

def get_match_summary(home: str, away: str) -> str:
    """ëª¨ì˜ ê²½ê¸° ìš”ì•½ì„ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    summary = {
        "home": home,
        "away": away,
        "score": "2-1",
        "events": [
            {"minute": 12, "team": home, "type": "goal", "player": "A. Kim"},
            {"minute": 45, "team": away, "type": "goal", "player": "J. Lee"},
            {"minute": 78, "team": home, "type": "goal", "player": "B. Park"},
        ],
        "summary_text": f"{home}ì´(ê°€) {away}ë¥¼ ìƒëŒ€ë¡œ ì—­ì „ìŠ¹ì„ ê±°ë‘ì—ˆìŠµë‹ˆë‹¤. ì „ë°˜ì—ëŠ” íŒ½íŒ½í–ˆìœ¼ë‚˜ í›„ë°˜ì— íë¦„ì„ ë°”ê¿¨ìŠµë‹ˆë‹¤."
    }
    return json.dumps(summary, ensure_ascii=False)

def get_player_stats(player_name: str) -> str:
    """ëª¨ì˜ ì„ ìˆ˜ í†µê³„ë¥¼ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    stats = {
        "player": player_name,
        "appearances": 24,
        "goals": 9,
        "assists": 6,
        "rating": 7.4,
        "notes": f"{player_name}ì€(ëŠ”) ì´ë²ˆ ì‹œì¦Œ í•µì‹¬ ê³µê²©ìˆ˜ë¡œ í™œì•½ ì¤‘ì…ë‹ˆë‹¤."
    }
    return json.dumps(stats, ensure_ascii=False)

def call_model(messages, temperature=0.5, max_tokens=700):
    if client is None:
        return "(ëª¨ë¸ í˜¸ì¶œ ë¶ˆê°€ â€” Azure í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨)"
    try:
        resp = client.chat.completions.create(
            model=DEPLOYMENT,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"(ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e})"

# UI: left = controls, right = conversation
col1, col2 = st.columns([1, 2])

with col1:
    st.header("ì§ˆë¬¸ ì…ë ¥")
    prompt = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", height=120, placeholder="ì˜ˆ: ì§€ë‚œ ë§¨ìœ  vs ë¦¬ë²„í’€ ê²½ê¸° ìš”ì•½í•´ì¤˜\nì˜ˆ: ì„ ìˆ˜ í†µê³„: ì†í¥ë¯¼")
    mode = st.selectbox("ëª¨ë“œ", ["Auto", "Soccer", "General"], index=0)
    temp = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.0, 0.3)
    send = st.button("ì „ì†¡")
    st.markdown("---")
    st.subheader("ë„êµ¬ í…ŒìŠ¤íŠ¸ (ëª¨ì˜)")
    t_home = st.text_input("í™ˆ íŒ€", "Manchester United")
    t_away = st.text_input("ì›ì • íŒ€", "Liverpool")
    if st.button("ëª¨ì˜ ê²½ê¸° ìš”ì•½ ìƒì„±"):
        st.json(json.loads(get_match_summary(t_home, t_away)))
    st.text("")
    p_name = st.text_input("ì„ ìˆ˜ ì´ë¦„ (í…ŒìŠ¤íŠ¸)", "Son Heung-min")
    if st.button("ëª¨ì˜ ì„ ìˆ˜ í†µê³„ ìƒì„±"):
        st.json(json.loads(get_player_stats(p_name)))

with col2:
    st.header("ëŒ€í™” / ì‘ë‹µ")
    if "history" not in st.session_state:
        st.session_state.history = []

    def append_history(role, text):
        st.session_state.history.append({"role": role, "content": text})

    # Display history
    for m in st.session_state.history:
        if m["role"] == "user":
            st.markdown(f"**ì‚¬ìš©ì:** {m['content']}")
        else:
            st.markdown(f"**Assistant:** {m['content']}")

    # Action when send
    if send and prompt:
        append_history("user", prompt)

        # Detect soccer intent
        is_soccer = mode == "Soccer" or (mode == "Auto" and any(k in prompt for k in SOCCER_KEYWORDS))

        if is_soccer:
            system = {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ SoccerBotì…ë‹ˆë‹¤. ì¶•êµ¬ì— ê´€í•´ ì „ë¬¸ì ì´ê³  ìƒì„¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤. "
                    "ê²½ê¸° ìš”ì•½, ì „ìˆ  ë¶„ì„, ì„ ìˆ˜ í†µê³„ ë° ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”. ì‚¬ì‹¤ ê¸°ë°˜ê³¼ ì˜ê²¬ì„ êµ¬ë¶„í•˜ê³ , í•„ìš”í•œ ê²½ìš° ì˜ˆìƒ ë¼ì¸ì—…ì´ë‚˜ ì „ìˆ ë„ ì œì•ˆí•˜ì„¸ìš”."
                )
            }

            # Simple pattern handling: 'ê²½ê¸° ìš”ì•½: TeamA vs TeamB' or 'ì„ ìˆ˜ í†µê³„: Name'
            m = re.search(r"ê²½ê¸° ìš”ì•½[:ï¼š]?\s*(.+?)\s+vs\s+(.+)", prompt, re.IGNORECASE)
            if m:
                home, away = m.group(1).strip(), m.group(2).strip()
                tool_out = get_match_summary(home, away)
                # Provide tool output as a tool-role message and ask model to expand
                messages = [system, {"role": "user", "content": prompt}, {"role": "tool", "name": "get_match_summary", "content": tool_out}]
                assistant_reply = call_model(messages, temperature=temp)
            else:
                m2 = re.search(r"ì„ ìˆ˜ í†µê³„[:ï¼š]?\s*(.+)", prompt, re.IGNORECASE)
                if m2:
                    player = m2.group(1).strip()
                    tool_out = get_player_stats(player)
                    messages = [system, {"role": "user", "content": prompt}, {"role": "tool", "name": "get_player_stats", "content": tool_out}]
                    assistant_reply = call_model(messages, temperature=temp)
                else:
                    # Generic soccer question â€” just pass system instruction + user prompt
                    messages = [system, {"role": "user", "content": prompt}]
                    assistant_reply = call_model(messages, temperature=temp)
        else:
            # General flow: use existing session messages
            messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.history]
            assistant_reply = call_model(messages, temperature=temp)

        append_history("assistant", assistant_reply)
        st.markdown(f"**Assistant:** {assistant_reply}")

    st.markdown("---")
    st.caption("íŒ: ì¶•êµ¬ ì „ë¬¸ ì‘ë‹µì„ ì›í•˜ë©´ 'ì„ ìˆ˜ í†µê³„: ì†í¥ë¯¼' ë˜ëŠ” 'ê²½ê¸° ìš”ì•½: ë§¨ìœ  vs ë¦¬ë²„í’€'ì²˜ëŸ¼ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

# ë
import streamlit as st
import os
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

st.title("ğŸ¤– ê²½ê¸° ê²°ê³¼ ë¶„ì„ Bot")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# (ì‹¤ì œ ê°’ì€ .env íŒŒì¼ì´ë‚˜ ì—¬ê¸°ì— ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”)
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™” - ì´ê²Œ ì—†ìœ¼ë©´ ìƒˆë¡œê³ ì¹¨ ë•Œë§ˆë‹¤ ëŒ€í™”ê°€ ë‚ ì•„ê°‘ë‹ˆë‹¤!
if "messages" not in st.session_state:
    st.session_state.messages = []

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì•„ë‹˜, ë‹¨ìˆœ í˜¸ì¶œ ì˜ˆì‹œ)
    with st.chat_message("assistant"):
        response = client.chat.completions.create(
            model="gpt-4o-mini", # ì‚¬ìš©í•˜ì‹œëŠ” ë°°í¬ëª…(Deployment Name)ìœ¼ë¡œ ìˆ˜ì • í•„ìš”!
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ]
        )
        assistant_reply = response.choices[0].message.content
        st.markdown(assistant_reply)

    # (3) AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

